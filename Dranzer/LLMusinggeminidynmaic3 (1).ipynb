{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\codes\\envs\\mygeminienv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "GOOGLE_API_KEY=\"AIzaSyB2pK2H6iyeUM3cUS92DhSwrJN-QjR4Gis\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY) # Pass the API key as a keyword argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb\n",
    "import urllib\n",
    "import warnings\n",
    "import certifi\n",
    "from pathlib import Path as p\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "#from requests.packages.urllib3.poolmanager import PoolManager\n",
    "import ssl\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUCHDB_URL = 'https://192.168.57.185:5984'  # Adjust if necessary\n",
    "COUCHDB_USERNAME = 'd_couchdb'\n",
    "COUCHDB_PASSWORD = 'Welcome#2'\n",
    "DATABASE_NAME = 'tamil_datalinkpro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to CouchDB server at https://192.168.57.185:5984\n"
     ]
    }
   ],
   "source": [
    "def connect_to_couchdb(url, username, password):\n",
    "    try:\n",
    "        auth = HTTPBasicAuth(username, password)\n",
    "        response = requests.get(url, auth=auth, verify=False)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Connected to CouchDB server at {url}\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error connecting to CouchDB server: {e}\")\n",
    "        return False\n",
    "\n",
    "# Connect to CouchDB server\n",
    "if not connect_to_couchdb(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD):\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"couchdb\":\"Welcome\",\"version\":\"3.3.2\",\"git_sha\":\"11a234070\",\"uuid\":\"a96c165907f626f26cb9b851f56a10d3\",\"features\":[\"search\",\"access-ready\",\"partitioned\",\"pluggable-storage-engines\",\"reshard\",\"scheduler\"],\"vendor\":{\"name\":\"The Apache Software Foundation\"}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "from requests.packages.urllib3.poolmanager import PoolManager\n",
    "\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "def connect_to_couchdb(url, username, password):\n",
    "    # Disable SSL warnings\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    # Setting up environment to bypass CA certificates (not recommended in production)\n",
    "    #os.environ['REQUESTS_CA_BUNDLE'] = ''\n",
    "\n",
    "    # Make a request to the CouchDB server with basic authentication\n",
    "    response = requests.get(url, auth=HTTPBasicAuth(username, password), verify=False)\n",
    "    \n",
    "    # Check if the response indicates an authentication issue\n",
    "    if response.status_code == 401:\n",
    "        print(\"Authentication failed: Unauthorized. Check your username and password.\")\n",
    "    else:\n",
    "        # Print the response for debugging\n",
    "        print(response.text)\n",
    "    \n",
    "    return response\n",
    "        \n",
    "db = connect_to_couchdb(COUCHDB_URL,COUCHDB_USERNAME,COUCHDB_PASSWORD)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_combine_data(main_doc_id, additional_info_doc_id, leave_doc_id):\n",
    "    \"\"\"\n",
    "    Retrieve and combine data from three documents.\n",
    "    \"\"\"\n",
    "    # Fetch documents\n",
    "    main_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, main_doc_id)\n",
    "    additional_info_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, additional_info_doc_id)\n",
    "    leave_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, leave_doc_id)\n",
    "\n",
    "    if not main_doc or not additional_info_doc or not leave_doc:\n",
    "        print(\"Error retrieving one or more documents.\")\n",
    "        return None\n",
    "\n",
    "    # Extract relevant data\n",
    "    employee_id = main_doc.get('data', {}).get('employee_id', 'N/A')\n",
    "    name = main_doc.get('data', {}).get('name', 'N/A')\n",
    "    additional_info = additional_info_doc.get('data', {})\n",
    "    leaves = leave_doc.get('leaves', [])\n",
    "\n",
    "    # Combine text\n",
    "    combined_text = (\n",
    "        f\"Employee ID: {employee_id}\\n\"\n",
    "        f\"Name: {name}\\n\"\n",
    "        f\"Additional Info ID: {additional_info.get('additionalinfo_id', 'N/A')}\\n\"\n",
    "        f\"Address: {additional_info.get('address', 'N/A')}\\n\"\n",
    "        f\"Leaves Taken:\\n\"\n",
    "    )\n",
    "\n",
    "    # Add leave details\n",
    "    if leaves:\n",
    "        for leave in leaves:\n",
    "            combined_text += (\n",
    "                f\"  - Date: {leave.get('date', 'N/A')}, \"\n",
    "                f\"Type: {leave.get('type', 'N/A')}\\n\"\n",
    "            )\n",
    "    else:\n",
    "        combined_text += \"  - No leaves recorded\\n\"\n",
    "\n",
    "    print(combined_text)\n",
    "    return combined_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 31ba3bd248aefe26d60d0a26c31511d8 updated and returned\n",
      "Document 31ba3bd248aefe26d60d0a26c314e406 updated and returned\n",
      "Document 31ba3bd248aefe26d60d0a26c31542b2 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa801f32b1 updated and returned\n",
      "Document 31ba3bd248aefe26d60d0a26c32b7d8d updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa801ee4b1 updated and returned\n",
      "Document 31ba3bd248aefe26d60d0a26c3152d82 updated and returned\n",
      "Document employee_3_XYZ12345 updated and returned\n",
      "Document 382 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa80209500 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa801f0bcd updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa8020a089 updated and returned\n",
      "Document employee_4_ABC12345 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa802225a0 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa801f4e01 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa80225233 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa801f6838 updated and returned\n",
      "Document employee_1_XYZ12345 updated and returned\n",
      "Document employee_001 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa8021605c updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa8020b7b2 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa80232aea updated and returned\n",
      "Document employee_1 updated and returned\n",
      "Document leave_2_001 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa8021ce1b updated and returned\n",
      "Document additionalinfo_1_001 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa8023be57 updated and returned\n",
      "Document additionalinfo_3_XYZ98765 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa8024031c updated and returned\n",
      "Document employee_2_002 updated and returned\n",
      "Error fetching document 2_002: 404 Client Error: Object Not Found for url: https://192.168.57.185:5984/tamil_datalinkpro/2_002\n",
      "Error retrieving one or more documents.\n",
      "Document fb1a27d07d16b2d714c09dfa8023e9f2 updated and returned\n",
      "Document additionalinfo_3_003 updated and returned\n",
      "Document fb1a27d07d16b2d714c09dfa80259c16 updated and returned\n",
      "Document leave_2_002 updated and returned\n",
      "Document employee_3_003 updated and returned\n",
      "Error fetching document 3_003: 404 Client Error: Object Not Found for url: https://192.168.57.185:5984/tamil_datalinkpro/3_003\n",
      "Error retrieving one or more documents.\n",
      "Document fb1a27d07d16b2d714c09dfa80287d40 updated and returned\n",
      "Document leave_1_001 updated and returned\n",
      "Document leave_3_003 updated and returned\n",
      "Document employee_1_001 updated and returned\n",
      "Error fetching document 1_001: 404 Client Error: Object Not Found for url: https://192.168.57.185:5984/tamil_datalinkpro/1_001\n",
      "Error retrieving one or more documents.\n",
      "Document leave_4_004 updated and returned\n",
      "Document additionalinfo_2_002 updated and returned\n",
      "Document ID or Document missing in change feed.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "import urllib3\n",
    "import json\n",
    "\n",
    "# Disable SSL warnings (not recommended for production)\n",
    "urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"def retrieve_and_combine_data(main_doc_id, additional_info_doc_id, leave_doc_id):\n",
    "    # Fetch documents\n",
    "    main_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, main_doc_id)\n",
    "    additional_info_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, additional_info_doc_id)\n",
    "    leave_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, leave_doc_id)\n",
    "\n",
    "    if not main_doc or not additional_info_doc or not leave_doc:\n",
    "        print(\"Error retrieving one or more documents.\")\n",
    "        return None\n",
    "\n",
    "    # Extract relevant data\n",
    "    employee_id = main_doc.get('data', {}).get('employee_id', 'N/A')\n",
    "    name = main_doc.get('data', {}).get('name', 'N/A')\n",
    "    additional_info = additional_info_doc.get('data', {})\n",
    "    leaves = leave_doc.get('leaves', [])\n",
    "\n",
    "    # Combine text\n",
    "    combined_text = (\n",
    "        f\"Employee ID: {employee_id}\\n\"\n",
    "        f\"Name: {name}\\n\"\n",
    "        f\"Additional Info ID: {additional_info.get('additionalinfo_id', 'N/A')}\\n\"\n",
    "        f\"Address: {additional_info.get('address', 'N/A')}\\n\"\n",
    "        f\"Leaves Taken:\\n\"\n",
    "    )\n",
    "\n",
    "    # Add leave details\n",
    "    if leaves:\n",
    "        for leave in leaves:\n",
    "            combined_text += (\n",
    "                f\"  - Date: {leave.get('date', 'N/A')}, \"\n",
    "                f\"Type: {leave.get('type', 'N/A')}\\n\"\n",
    "            )\n",
    "    else:\n",
    "        combined_text += \"  - No leaves recorded\\n\"\n",
    "    print(combined_text)\n",
    "    return combined_text\n",
    "    \"\"\"\n",
    "def listen_to_changes(url, username, password):\n",
    "    if not url:\n",
    "        print(\"Invalid URL.\")\n",
    "        return\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Listen to the changes feed\n",
    "        with requests.get(f\"{url}/{DATABASE_NAME}/_changes?feed=continuous&include_docs=true\", \n",
    "                          auth=HTTPBasicAuth(username, password), \n",
    "                          headers=headers, \n",
    "                          verify=False, \n",
    "                          stream=True) as response:\n",
    "            for line in response.iter_lines(decode_unicode=True):\n",
    "                if line:\n",
    "                    change = json.loads(line)\n",
    "                    doc_id = change.get('id')\n",
    "                    doc = change.get('doc')\n",
    "\n",
    "                    if doc_id and doc:\n",
    "                        print(f\"Document {doc_id} updated and returned\")\n",
    "\n",
    "                        # Fetch related documents based on IDs found in the change feed\n",
    "                        if 'data' in doc:\n",
    "                            main_doc_id = doc.get('_id')\n",
    "                            additional_info_doc_id = doc.get('data', {}).get('additionalinfo_id')\n",
    "                            leave_doc_id = doc.get('data', {}).get('employee_id')  # Assuming leave doc ID matches employee ID\n",
    "\n",
    "                            if main_doc_id and additional_info_doc_id and leave_doc_id:\n",
    "                                combined_data = retrieve_and_combine_data(main_doc_id, additional_info_doc_id, leave_doc_id)\n",
    "                                if combined_data:\n",
    "                                    print(\"processing the document:\\t\",combined_data)\n",
    "                    else:\n",
    "                        print(f\"Document ID or Document missing in change feed.\")\n",
    "             \n",
    "    except Exception as e:\n",
    "        print(f\"Error in listening to changes: {e}\")\n",
    "\n",
    "listen_to_changes(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Document ID: additionalinfo_1_001\n",
      "Additional Info Document ID: additionalinfo_2_002\n",
      "Leave Document ID: additionalinfo_3_003\n"
     ]
    }
   ],
   "source": [
    "def fetch_all_document_ids(url, username, password, database_name):\n",
    "    \"\"\"\n",
    "    Fetch all document IDs from a CouchDB database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/{database_name}/_all_docs?include_docs=false\",\n",
    "                                auth=HTTPBasicAuth(username, password),\n",
    "                                verify=False)\n",
    "        response.raise_for_status()  # Raise an error for bad HTTP status\n",
    "        \n",
    "        data = response.json()\n",
    "        document_ids = [row['id'] for row in data.get('rows', [])]\n",
    "\n",
    "        return document_ids\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching document IDs: {e}\")\n",
    "        return []\n",
    "    \n",
    "\n",
    "document_ids = fetch_all_document_ids(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, DATABASE_NAME)\n",
    "\n",
    "# Store document IDs in named variables\n",
    "main_id = None\n",
    "additional_info_id = None\n",
    "leave_id = None\n",
    "\n",
    "if len(document_ids) > 0:\n",
    "    main_id = document_ids[0]\n",
    "\n",
    "if len(document_ids) > 1:\n",
    "    additional_info_id = document_ids[1]\n",
    "\n",
    "if len(document_ids) > 2:\n",
    "    leave_id = document_ids[2]\n",
    "\n",
    "# Print the stored document IDs\n",
    "print(f\"Main Document ID: {main_id}\")\n",
    "print(f\"Additional Info Document ID: {additional_info_id}\")\n",
    "print(f\"Leave Document ID: {leave_id}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_document(url, username, password, doc_id):\n",
    "    \"\"\"\n",
    "    Fetch a document from CouchDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/{DATABASE_NAME}/{doc_id}\", \n",
    "                                auth=HTTPBasicAuth(username, password), \n",
    "                                verify=False)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching document {doc_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_combine_data(main_doc_id, additional_info_doc_id, leave_doc_id):\n",
    "    \"\"\"\n",
    "    Retrieve and combine data from three documents.\n",
    "    \"\"\"\n",
    "    # Fetch documents\n",
    "    main_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, main_doc_id)\n",
    "    additional_info_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, additional_info_doc_id)\n",
    "    leave_doc = fetch_document(COUCHDB_URL, COUCHDB_USERNAME, COUCHDB_PASSWORD, leave_doc_id)\n",
    "\n",
    "    if not main_doc or not additional_info_doc or not leave_doc:\n",
    "        print(\"Error retrieving one or more documents.\")\n",
    "        return None\n",
    "\n",
    "    # Extract relevant data\n",
    "    employee_id = main_doc.get('data', {}).get('employee_id', 'N/A')\n",
    "    name = main_doc.get('data', {}).get('name', 'N/A')\n",
    "    additional_info = additional_info_doc.get('data', {})\n",
    "    leaves = leave_doc.get('leaves', [])\n",
    "\n",
    "    # Combine text\n",
    "    combined_text = (\n",
    "        f\"Employee ID: {employee_id}\\n\"\n",
    "        f\"Name: {name}\\n\"\n",
    "        f\"Additional Info ID: {additional_info.get('additionalinfo_id', 'N/A')}\\n\"\n",
    "        f\"Address: {additional_info.get('address', 'N/A')}\\n\"\n",
    "        f\"Leaves Taken:\\n\"\n",
    "    )\n",
    "\n",
    "    # Add leave details\n",
    "    if leaves:\n",
    "        for leave in leaves:\n",
    "            combined_text += (\n",
    "                f\"  - Date: {leave.get('date', 'N/A')}, \"\n",
    "                f\"Type: {leave.get('type', 'N/A')}\\n\"\n",
    "            )\n",
    "    else:\n",
    "        combined_text += \"  - No leaves recorded\\n\"\n",
    "\n",
    "    print(combined_text)\n",
    "    return combined_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CouchDB connection parameters\n",
    "COUCHDB_URL = 'https://192.168.57.185:5984'\n",
    "COUCHDB_USERNAME = 'd_couchdb'\n",
    "COUCHDB_PASSWORD = 'Welcome#2'\n",
    "DATABASE_NAME = 'tamil_datalinkpro'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_text(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=GOOGLE_API_KEY)\n",
    "     \n",
    "\n",
    "vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# Replace 'YOUR_GOOGLE_API_KEY' with your actual API key\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=\"AIzaSyB2pK2H6iyeUM3cUS92DhSwrJN-QjR4Gis\") \n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  # Pass the initialized language model here\n",
    "    retriever=vector_index,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"list all the employees whose name starts with J\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
